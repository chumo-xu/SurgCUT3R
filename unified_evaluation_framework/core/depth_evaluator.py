"""
æ·±åº¦è¯„ä¼°æ ¸å¿ƒæ¨¡å—
ä¸¥æ ¼æŒ‰ç…§ç»Ÿä¸€è¯„ä¼°æ ‡å‡†å®ç°æ·±åº¦è¯„ä¼°æµç¨‹
"""

import numpy as np
import cv2
from typing import Dict, List, Tuple, Any
from tqdm import tqdm

from core.utils import (
    resize_depth, create_depth_mask, median_scale_alignment, 
    compute_statistics, log_evaluation_info, validate_input_shapes
)


def compute_depth_errors(gt: np.ndarray, pred: np.ndarray) -> Dict[str, float]:
    """
    è®¡ç®—æ·±åº¦ä¼°è®¡è¯¯å·®æŒ‡æ ‡ï¼ˆä¸EndoDACæ ‡å‡†ä¸€è‡´ï¼‰
    
    Args:
        gt: GTæ·±åº¦å€¼ (æœ‰æ•ˆåƒç´ )
        pred: é¢„æµ‹æ·±åº¦å€¼ (æœ‰æ•ˆåƒç´ )
    
    Returns:
        è¯¯å·®æŒ‡æ ‡å­—å…¸
    """
    # è®¡ç®—é˜ˆå€¼æŒ‡æ ‡
    thresh = np.maximum((gt / pred), (pred / gt))
    a1 = (thresh < 1.25).mean()
    a2 = (thresh < 1.25 ** 2).mean() 
    a3 = (thresh < 1.25 ** 3).mean()

    # è®¡ç®—RMSEæŒ‡æ ‡
    rmse = np.sqrt(np.mean((gt - pred) ** 2))
    rmse_log = np.sqrt(np.mean((np.log(gt) - np.log(pred)) ** 2))

    # è®¡ç®—ç›¸å¯¹è¯¯å·®æŒ‡æ ‡
    abs_rel = np.mean(np.abs(gt - pred) / gt)
    sq_rel = np.mean(((gt - pred) ** 2) / gt)

    return {
        'abs_rel': float(abs_rel),
        'sq_rel': float(sq_rel), 
        'rmse': float(rmse),
        'rmse_log': float(rmse_log),
        'a1': float(a1),
        'a2': float(a2),
        'a3': float(a3)
    }


class DepthEvaluator:
    """
    æ·±åº¦è¯„ä¼°å™¨ - ç»Ÿä¸€æ·±åº¦è¯„ä¼°æ ‡å‡†
    
    è¯„ä¼°æµç¨‹:
    1. è°ƒæ•´åˆ°GTå°ºå¯¸
    2. åˆ›å»ºæœ‰æ•ˆæ©ç  (1e-3åˆ°150m)
    3. ä¸­å€¼ç¼©æ”¾å¯¹é½ 
    4. æ·±åº¦èŒƒå›´æˆªæ–­
    5. è®¡ç®—è¯¯å·®æŒ‡æ ‡
    """
    
    def __init__(self, min_depth: float = 1e-3, max_depth: float = 150.0, 
                 min_valid_pixels: int = 1000, verbose: bool = True):
        """
        åˆå§‹åŒ–æ·±åº¦è¯„ä¼°å™¨
        
        Args:
            min_depth: æœ€å°æœ‰æ•ˆæ·±åº¦ (m)
            max_depth: æœ€å¤§æœ‰æ•ˆæ·±åº¦ (m)
            min_valid_pixels: æœ€å°æœ‰æ•ˆåƒç´ æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.min_depth = min_depth
        self.max_depth = max_depth
        self.min_valid_pixels = min_valid_pixels
        self.verbose = verbose
        
        log_evaluation_info(f"æ·±åº¦è¯„ä¼°å™¨åˆå§‹åŒ– - æœ‰æ•ˆæ·±åº¦èŒƒå›´: {min_depth:.1e}~{max_depth:.1f}m", verbose)
    
    def evaluate_frame(self, gt_depth: np.ndarray, pred_depth: np.ndarray) -> Tuple[Dict[str, float], Dict[str, Any]]:
        """
        è¯„ä¼°å•å¸§æ·±åº¦
        
        Args:
            gt_depth: (H, W) GTæ·±åº¦å›¾ï¼Œå•ä½m
            pred_depth: (H', W') é¢„æµ‹æ·±åº¦å›¾ï¼Œå•ä½m
        
        Returns:
            è¯¯å·®æŒ‡æ ‡, å¤„ç†ä¿¡æ¯
        """
        processing_info = {}
        
        # æ­¥éª¤1: è°ƒæ•´åˆ°GTå°ºå¯¸
        target_height, target_width = gt_depth.shape
        if pred_depth.shape != gt_depth.shape:
            pred_depth_resized = resize_depth(pred_depth, (target_height, target_width))
            processing_info['resized'] = True
            processing_info['original_shape'] = pred_depth.shape
            processing_info['target_shape'] = (target_height, target_width)
        else:
            pred_depth_resized = pred_depth.copy()
            processing_info['resized'] = False
        
        # æ­¥éª¤2: åˆ›å»ºæœ‰æ•ˆæ©ç  (1e-3åˆ°150mèŒƒå›´)
        mask = create_depth_mask(gt_depth, pred_depth_resized, self.min_depth, self.max_depth)
        valid_pixels = np.sum(mask)
        processing_info['valid_pixels'] = int(valid_pixels)
        
        if valid_pixels < self.min_valid_pixels:
            raise ValueError(f"æœ‰æ•ˆåƒç´ æ•°å¤ªå°‘: {valid_pixels} < {self.min_valid_pixels}")
        
        # æ­¥éª¤3: ä¸­å€¼ç¼©æ”¾å¯¹é½
        try:
            pred_depth_scaled, scale_ratio = median_scale_alignment(gt_depth, pred_depth_resized, mask)
            processing_info['scale_ratio'] = float(scale_ratio)
        except ValueError as e:
            raise ValueError(f"ç¼©æ”¾å¯¹é½å¤±è´¥: {e}")
        
        # æ­¥éª¤4: æ·±åº¦èŒƒå›´æˆªæ–­ (é™åˆ¶é¢„æµ‹æ·±åº¦çš„æå€¼)
        pred_depth_clipped = np.clip(pred_depth_scaled, self.min_depth, self.max_depth)
        
        # æ­¥éª¤5: é‡æ–°åˆ›å»ºæœ€ç»ˆæ©ç ï¼Œç¡®ä¿é¢„æµ‹å’ŒçœŸå®æ·±åº¦éƒ½åœ¨åˆç†èŒƒå›´å†…
        final_mask = create_depth_mask(gt_depth, pred_depth_clipped, self.min_depth, self.max_depth)
        final_valid_pixels = np.sum(final_mask)
        processing_info['final_valid_pixels'] = int(final_valid_pixels)
        
        if final_valid_pixels < self.min_valid_pixels // 2:  # å®¹å¿æœ€ç»ˆæœ‰æ•ˆåƒç´ å‡å°‘
            raise ValueError(f"æœ€ç»ˆæœ‰æ•ˆåƒç´ æ•°å¤ªå°‘: {final_valid_pixels}")
        
        # åº”ç”¨æœ€ç»ˆæ©ç 
        gt_final = gt_depth[final_mask]
        pred_final = pred_depth_clipped[final_mask]
        
        # è®¡ç®—è¯¯å·®æŒ‡æ ‡
        errors = compute_depth_errors(gt_final, pred_final)
        
        return errors, processing_info
    
    def evaluate_segment(self, gt_depths: np.ndarray, pred_depths: np.ndarray, segment_id: int = 0) -> Tuple[Dict[str, float], Dict[str, Any]]:
        """
        è¯„ä¼°å•ä¸ª16å¸§åˆ†æ®µçš„æ·±åº¦
        
        Args:
            gt_depths: (N, H, W) GTæ·±åº¦åˆ†æ®µï¼Œå•ä½m (N <= 16)
            pred_depths: (N, H', W') é¢„æµ‹æ·±åº¦åˆ†æ®µï¼Œå•ä½m
            segment_id: åˆ†æ®µIDç”¨äºæ—¥å¿—
        
        Returns:
            åˆ†æ®µå¹³å‡è¯¯å·®æŒ‡æ ‡, å¤„ç†ä¿¡æ¯
        """
        num_frames = len(gt_depths)
        log_evaluation_info(f"è¯„ä¼°åˆ†æ®µ{segment_id} ({num_frames}å¸§)", self.verbose)
        
        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆåƒç´ è¿›è¡Œç»Ÿä¸€ä¸­å€¼ç¼©æ”¾
        all_gt_valid = []
        all_pred_valid = []
        frame_masks = []
        
        target_height, target_width = gt_depths[0].shape
        
        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰æœ‰æ•ˆåƒç´ 
        for i in range(num_frames):
            gt_depth = gt_depths[i]
            pred_depth = pred_depths[i]
            
            # è°ƒæ•´åˆ°GTå°ºå¯¸
            if pred_depth.shape != gt_depth.shape:
                pred_depth = resize_depth(pred_depth, (target_height, target_width))
            
            # åˆ›å»ºæœ‰æ•ˆæ©ç 
            mask = create_depth_mask(gt_depth, pred_depth, self.min_depth, self.max_depth)
            
            if np.sum(mask) > 0:
                all_gt_valid.extend(gt_depth[mask])
                all_pred_valid.extend(pred_depth[mask])
                frame_masks.append(mask)
            else:
                frame_masks.append(None)
        
        if len(all_gt_valid) == 0:
            raise ValueError(f"åˆ†æ®µ{segment_id}æ²¡æœ‰æœ‰æ•ˆåƒç´ ")
        
        # ç¬¬äºŒæ­¥ï¼šè®¡ç®—åˆ†æ®µç»Ÿä¸€çš„ä¸­å€¼ç¼©æ”¾å› å­
        all_gt_valid = np.array(all_gt_valid)
        all_pred_valid = np.array(all_pred_valid)
        
        try:
            scale_ratio = np.median(all_gt_valid) / np.median(all_pred_valid)
        except:
            raise ValueError(f"åˆ†æ®µ{segment_id}ä¸­å€¼ç¼©æ”¾è®¡ç®—å¤±è´¥")
        
        # ç¬¬ä¸‰æ­¥ï¼šå¯¹æ¯å¸§åº”ç”¨ç»Ÿä¸€ç¼©æ”¾å¹¶è®¡ç®—æŒ‡æ ‡
        segment_errors = []
        
        for i in range(num_frames):
            if frame_masks[i] is None:
                continue
                
            gt_depth = gt_depths[i]
            pred_depth = pred_depths[i]
            
            # è°ƒæ•´å°ºå¯¸
            if pred_depth.shape != gt_depth.shape:
                pred_depth = resize_depth(pred_depth, (target_height, target_width))
            
            # åº”ç”¨ç»Ÿä¸€ç¼©æ”¾
            pred_depth_scaled = pred_depth * scale_ratio
            
            # æ·±åº¦æˆªæ–­
            pred_depth_clipped = np.clip(pred_depth_scaled, self.min_depth, self.max_depth)
            
            # æœ€ç»ˆæ©ç 
            final_mask = create_depth_mask(gt_depth, pred_depth_clipped, self.min_depth, self.max_depth)
            
            if np.sum(final_mask) > 0:
                gt_final = gt_depth[final_mask]
                pred_final = pred_depth_clipped[final_mask]
                
                # è®¡ç®—å•å¸§è¯¯å·®
                frame_error = compute_depth_errors(gt_final, pred_final)
                segment_errors.append(frame_error)
        
        if len(segment_errors) == 0:
            raise ValueError(f"åˆ†æ®µ{segment_id}æ²¡æœ‰æˆåŠŸè¯„ä¼°ä»»ä½•å¸§")
        
        # ç¬¬å››æ­¥ï¼šè®¡ç®—åˆ†æ®µå¹³å‡æŒ‡æ ‡
        metrics_names = ['abs_rel', 'sq_rel', 'rmse', 'rmse_log', 'a1', 'a2', 'a3']
        segment_metrics = {}
        
        for name in metrics_names:
            values = [err[name] for err in segment_errors]
            segment_metrics[name] = float(np.mean(values))
        
        processing_info = {
            'segment_id': segment_id,
            'num_frames': num_frames,
            'valid_frames': len(segment_errors),
            'scale_ratio': float(scale_ratio),
            'total_valid_pixels': len(all_gt_valid)
        }
        
        return segment_metrics, processing_info
    
    def evaluate_segmented(self, gt_depths: np.ndarray, pred_depths: np.ndarray, segment_size: int = 16) -> Dict[str, Any]:
        """
        åˆ†æ®µè¯„ä¼°æ·±åº¦åºåˆ—ï¼ˆæ¯æ®µç‹¬ç«‹ä¸­å€¼ç¼©æ”¾ï¼‰
        
        Args:
            gt_depths: (N, H, W) GTæ·±åº¦åºåˆ—ï¼Œå•ä½m
            pred_depths: (N, H', W') é¢„æµ‹æ·±åº¦åºåˆ—ï¼Œå•ä½m
            segment_size: åˆ†æ®µå¤§å°ï¼Œé»˜è®¤16å¸§
        
        Returns:
            åˆ†æ®µè¯„ä¼°ç»“æœ
        """
        log_evaluation_info(f"ğŸ¯ å¼€å§‹åˆ†æ®µæ·±åº¦è¯„ä¼° (æ¯{segment_size}å¸§ä¸€æ®µ)", self.verbose)
        
        # éªŒè¯è¾“å…¥
        validate_input_shapes(gt_depths, pred_depths, 'depth')
        num_frames = len(gt_depths)
        num_segments = (num_frames + segment_size - 1) // segment_size  # å‘ä¸Šå–æ•´
        
        log_evaluation_info(f"æ€»å¸§æ•°: {num_frames}, åˆ†æ®µæ•°: {num_segments}", self.verbose)
        
        # é€æ®µè¯„ä¼°
        segment_metrics = []
        segment_info = []
        failed_segments = []
        
        for seg_id in tqdm(range(num_segments), desc="è¯„ä¼°åˆ†æ®µ", disable=not self.verbose):
            start_idx = seg_id * segment_size
            end_idx = min(start_idx + segment_size, num_frames)
            
            gt_segment = gt_depths[start_idx:end_idx]
            pred_segment = pred_depths[start_idx:end_idx]
            
            try:
                metrics, info = self.evaluate_segment(gt_segment, pred_segment, seg_id)
                segment_metrics.append(metrics)
                segment_info.append(info)
                
            except ValueError as e:
                if self.verbose:
                    log_evaluation_info(f"åˆ†æ®µ{seg_id} [{start_idx}-{end_idx-1}] è¯„ä¼°å¤±è´¥: {e}", self.verbose)
                failed_segments.append(seg_id)
                continue
        
        if len(segment_metrics) == 0:
            raise ValueError("æ²¡æœ‰æˆåŠŸè¯„ä¼°ä»»ä½•åˆ†æ®µ")
        
        # æ±‡æ€»æ‰€æœ‰åˆ†æ®µçš„å¹³å‡æŒ‡æ ‡
        valid_segments = len(segment_metrics)
        success_rate = valid_segments / num_segments
        
        log_evaluation_info(f"æˆåŠŸè¯„ä¼°: {valid_segments}/{num_segments} åˆ†æ®µ ({success_rate:.1%})", self.verbose)
        
        # è®¡ç®—æœ€ç»ˆå¹³å‡æŒ‡æ ‡
        metrics_names = ['abs_rel', 'sq_rel', 'rmse', 'rmse_log', 'a1', 'a2', 'a3']
        final_metrics = {}
        
        for name in metrics_names:
            values = [metrics[name] for metrics in segment_metrics]
            final_metrics[name] = compute_statistics(np.array(values))
        
        # å¤„ç†ä¿¡æ¯ç»Ÿè®¡
        scale_ratios = [info['scale_ratio'] for info in segment_info]
        scale_stats = compute_statistics(np.array(scale_ratios))
        
        # æ„é€ ç»“æœ
        results = {
            'depth_metrics': final_metrics,
            'evaluation_info': {
                'total_frames': num_frames,
                'total_segments': num_segments,
                'valid_segments': valid_segments,
                'success_rate': success_rate,
                'failed_segments': failed_segments,
                'segment_size': segment_size,
                'processing_pipeline': {
                    'min_depth_m': self.min_depth,
                    'max_depth_m': self.max_depth,
                    'resize_to_gt': True,
                    'segmented_median_scale_alignment': True,
                    'depth_range_clipping': True
                }
            },
            'processing_stats': {
                'scale_alignment': scale_stats,
                'avg_frames_per_segment': float(np.mean([info['num_frames'] for info in segment_info]))
            },
            'per_segment_data': {
                'metrics': segment_metrics,
                'processing_info': segment_info
            }
        }
        
        log_evaluation_info("âœ… åˆ†æ®µæ·±åº¦è¯„ä¼°å®Œæˆ", self.verbose)
        return results

    def evaluate(self, gt_depths: np.ndarray, pred_depths: np.ndarray, mode: str = 'global') -> Dict[str, Any]:
        """
        è¯„ä¼°æ·±åº¦åºåˆ—
        
        Args:
            gt_depths: (N, H, W) GTæ·±åº¦åºåˆ—ï¼Œå•ä½m
            pred_depths: (N, H', W') é¢„æµ‹æ·±åº¦åºåˆ—ï¼Œå•ä½m
            mode: è¯„ä¼°æ¨¡å¼ ('global'=å…¨å±€ä¸­å€¼ç¼©æ”¾, 'segmented'=åˆ†æ®µä¸­å€¼ç¼©æ”¾, 'both'=ä¸¤ç§æ–¹æ³•)
        
        Returns:
            å®Œæ•´è¯„ä¼°ç»“æœ
        """
        if mode == 'segmented':
            return self.evaluate_segmented(gt_depths, pred_depths)
        elif mode == 'both':
            log_evaluation_info("ğŸ¯ å¼€å§‹åŒé‡æ·±åº¦è¯„ä¼° (å…¨å±€ + åˆ†æ®µ)", self.verbose)
            
            # å…¨å±€è¯„ä¼°
            global_results = self.evaluate_global(gt_depths, pred_depths)
            
            # åˆ†æ®µè¯„ä¼°  
            segmented_results = self.evaluate_segmented(gt_depths, pred_depths)
            
            # åˆå¹¶ç»“æœ
            combined_results = {
                'depth_metrics_global': global_results['depth_metrics'],
                'depth_metrics_segmented': segmented_results['depth_metrics'],
                'evaluation_info': {
                    'mode': 'both',
                    'global_info': global_results['evaluation_info'],
                    'segmented_info': segmented_results['evaluation_info']
                },
                'processing_stats': {
                    'global_stats': global_results['processing_stats'],
                    'segmented_stats': segmented_results['processing_stats']
                }
            }
            
            log_evaluation_info("âœ… åŒé‡æ·±åº¦è¯„ä¼°å®Œæˆ", self.verbose)
            return combined_results
        else:
            # é»˜è®¤å…¨å±€æ¨¡å¼
            return self.evaluate_global(gt_depths, pred_depths)
    
    def evaluate_global(self, gt_depths: np.ndarray, pred_depths: np.ndarray) -> Dict[str, Any]:
        """
        å…¨å±€è¯„ä¼°æ·±åº¦åºåˆ—ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰
        
        Args:
            gt_depths: (N, H, W) GTæ·±åº¦åºåˆ—ï¼Œå•ä½m
            pred_depths: (N, H', W') é¢„æµ‹æ·±åº¦åºåˆ—ï¼Œå•ä½m
        
        Returns:
            å®Œæ•´è¯„ä¼°ç»“æœ
        """
        log_evaluation_info("ğŸ¯ å¼€å§‹å…¨å±€æ·±åº¦è¯„ä¼°", self.verbose)
        
        # éªŒè¯è¾“å…¥
        validate_input_shapes(gt_depths, pred_depths, 'depth')
        num_frames = len(gt_depths)
        
        log_evaluation_info(f"æ€»å¸§æ•°: {num_frames}", self.verbose)
        log_evaluation_info(f"GTå°ºå¯¸: {gt_depths.shape}", self.verbose)
        log_evaluation_info(f"é¢„æµ‹å°ºå¯¸: {pred_depths.shape}", self.verbose)
        
        # é€å¸§è¯„ä¼°
        frame_errors = []
        frame_info = []
        skipped_frames = []
        
        for i in tqdm(range(num_frames), desc="è¯„ä¼°æ·±åº¦å¸§", disable=not self.verbose):
            try:
                errors, info = self.evaluate_frame(gt_depths[i], pred_depths[i])
                frame_errors.append(errors)
                frame_info.append(info)
                
            except ValueError as e:
                if self.verbose:
                    log_evaluation_info(f"è·³è¿‡ç¬¬{i}å¸§: {e}", self.verbose)
                skipped_frames.append(i)
                continue
        
        if len(frame_errors) == 0:
            raise ValueError("æ²¡æœ‰æˆåŠŸè¯„ä¼°ä»»ä½•å¸§")
        
        # æ±‡æ€»ç»“æœ
        valid_frames = len(frame_errors)
        success_rate = valid_frames / num_frames
        
        log_evaluation_info(f"æˆåŠŸè¯„ä¼°: {valid_frames}/{num_frames} å¸§ ({success_rate:.1%})", self.verbose)
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        metrics_names = ['abs_rel', 'sq_rel', 'rmse', 'rmse_log', 'a1', 'a2', 'a3']
        
        # æ”¶é›†æ¯ä¸ªæŒ‡æ ‡çš„æ‰€æœ‰å¸§æ•°æ®
        metrics_data = {name: [] for name in metrics_names}
        for errors in frame_errors:
            for name in metrics_names:
                metrics_data[name].append(errors[name])
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        final_metrics = {}
        for name in metrics_names:
            values = np.array(metrics_data[name])
            final_metrics[name] = compute_statistics(values)
        
        # å¤„ç†ä¿¡æ¯ç»Ÿè®¡
        scale_ratios = [info['scale_ratio'] for info in frame_info]
        scale_stats = compute_statistics(np.array(scale_ratios))
        
        valid_pixels = [info['valid_pixels'] for info in frame_info]
        final_valid_pixels = [info['final_valid_pixels'] for info in frame_info]
        
        # æ„é€ æœ€ç»ˆç»“æœ
        results = {
            'depth_metrics': final_metrics,
            'evaluation_info': {
                'total_frames': num_frames,
                'valid_frames': valid_frames,
                'success_rate': success_rate,
                'skipped_frames': skipped_frames,
                'processing_pipeline': {
                    'min_depth_m': self.min_depth,
                    'max_depth_m': self.max_depth,
                    'resize_to_gt': True,
                    'median_scale_alignment': True,
                    'depth_range_clipping': True
                }
            },
            'processing_stats': {
                'scale_alignment': scale_stats,
                'avg_valid_pixels': float(np.mean(valid_pixels)),
                'avg_final_valid_pixels': float(np.mean(final_valid_pixels))
            },
            'per_frame_data': {
                'errors': frame_errors,
                'processing_info': frame_info
            }
        }
        
        log_evaluation_info("âœ… å…¨å±€æ·±åº¦è¯„ä¼°å®Œæˆ", self.verbose)
        return results
    
    def print_results(self, results: Dict[str, Any]) -> None:
        """
        æ‰“å°è¯„ä¼°ç»“æœæ‘˜è¦
        
        Args:
            results: è¯„ä¼°ç»“æœ
        """
        print("\n" + "="*70)
        print("ğŸ¯ æ·±åº¦è¯„ä¼°ç»“æœæ‘˜è¦")
        print("="*70)
        
        # åŸºæœ¬ä¿¡æ¯
        info = results['evaluation_info']
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†æ®µè¯„ä¼°ç»“æœ
        if 'valid_segments' in info:
            # åˆ†æ®µè¯„ä¼°ç»“æœ
            print(f"è¯„ä¼°åˆ†æ®µæ•°: {info['valid_segments']}/{info['total_segments']} ({info['success_rate']:.1%})")
            print(f"åˆ†æ®µå¤§å°: {info['segment_size']}å¸§")
        else:
            # å…¨å±€è¯„ä¼°ç»“æœ
            print(f"è¯„ä¼°å¸§æ•°: {info['valid_frames']}/{info['total_frames']} ({info['success_rate']:.1%})")
        
        # å¤„ç†ç»Ÿè®¡
        scale_stats = results['processing_stats']['scale_alignment']
        print(f"ç¼©æ”¾æ¯”ä¾‹: {scale_stats['mean']:.3f} Â± {scale_stats['std']:.3f}")
        
        # ä¸»è¦æŒ‡æ ‡
        print(f"\nğŸ“Š å®Œæ•´æŒ‡æ ‡ (mean Â± std):")
        metrics = results['depth_metrics']
        print(f"  abs_rel:  {metrics['abs_rel']['mean']:.3f} Â± {metrics['abs_rel']['std']:.3f}")
        print(f"  sq_rel:   {metrics['sq_rel']['mean']*1000:.6f} Â± {metrics['sq_rel']['std']*1000:.6f} mm")
        print(f"  rmse:     {metrics['rmse']['mean']*1000:.4f} Â± {metrics['rmse']['std']*1000:.4f} mm")
        print(f"  rmse_log: {metrics['rmse_log']['mean']:.3f} Â± {metrics['rmse_log']['std']:.3f}")
        print(f"  a1:       {metrics['a1']['mean']:.3f} Â± {metrics['a1']['std']:.3f}")
        print(f"  a2:       {metrics['a2']['mean']:.3f} Â± {metrics['a2']['std']:.3f}")
        print(f"  a3:       {metrics['a3']['mean']:.3f} Â± {metrics['a3']['std']:.3f}")
        
        # æ€§èƒ½è¯„çº§
        a1_mean = metrics['a1']['mean']
        if a1_mean > 0.8:
            grade = "ä¼˜ç§€ (Sçº§)"
        elif a1_mean > 0.6:
            grade = "è‰¯å¥½ (Açº§)"
        else:
            grade = "æœ‰å¾…æ”¹è¿› (Bçº§)"
        
        print(f"\nğŸ† æ€§èƒ½è¯„çº§: {grade} (a1={a1_mean:.3f})")
        print("="*70)
