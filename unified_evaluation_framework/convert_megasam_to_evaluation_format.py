#!/usr/bin/env python3
"""
MegaSAMç»“æœæ ¼å¼è½¬æ¢è„šæœ¬
å°†MegaSAMçš„æ·±åº¦å’Œä½å§¿ç»“æœè½¬æ¢ä¸ºCUT3Rè¯„ä¼°ä»£ç éœ€è¦çš„æ ¼å¼
"""

import os
import numpy as np
from pathlib import Path
from tqdm import tqdm


class MegaSAMResultConverter:
    """MegaSAMç»“æœè½¬æ¢å™¨"""
    
    def __init__(self):
        # è¾“å…¥è·¯å¾„
        self.megasam_input_dir = "/hy-tmp/hy-tmp/CUT3R/eval/megasam/hy-tmp/mega-sam/outputs_cvd"
        
        # è¾“å‡ºè·¯å¾„
        self.output_base = "/hy-tmp/hy-tmp/CUT3R/eval/megasam/megasam_results"
        
        # æ–‡ä»¶ååˆ°åºåˆ—åçš„æ˜ å°„
        self.file_mappings = {
            "Scared8_0_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset8_keyframe0",
            "Scared8_1_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset8_keyframe1", 
            "Scared8_2_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset8_keyframe2",
            "Scared8_3_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset8_keyframe3",
            "Scared9_0_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset9_keyframe0",
            "Scared9_1_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset9_keyframe1",
            "Scared9_2_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset9_keyframe2",
            "Scared9_3_Left_Images_sgd_cvd_hr.npz": "dual_evaluation_dataset9_keyframe3",
        }
    
    def validate_input_files(self):
        """éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("ğŸ” éªŒè¯è¾“å…¥æ–‡ä»¶...")
        
        missing_files = []
        
        for filename in self.file_mappings.keys():
            file_path = os.path.join(self.megasam_input_dir, filename)
            if not os.path.exists(file_path):
                missing_files.append(filename)
        
        if missing_files:
            print("âŒ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶:")
            for filename in missing_files:
                print(f"   {filename}")
            return False
        
        print("âœ… æ‰€æœ‰è¾“å…¥æ–‡ä»¶éªŒè¯æˆåŠŸ")
        return True
    
    def extract_depth_data(self, depths_array, target_dir):
        """
        æå–æ·±åº¦æ•°æ®ä¸ºå•ç‹¬çš„npyæ–‡ä»¶
        ä» (N, H, W) â†’ 000000.npy, 000001.npy, ...
        """
        os.makedirs(target_dir, exist_ok=True)
        
        num_frames = depths_array.shape[0]
        print(f"  æå– {num_frames} å¸§æ·±åº¦æ•°æ®...")
        
        for i in tqdm(range(num_frames), desc="  æ·±åº¦å¸§"):
            # æ ¼å¼åŒ–å¸§å·ä¸º6ä½æ•°å­—
            frame_filename = f"{i:06d}.npy"
            frame_path = os.path.join(target_dir, frame_filename)
            
            # ä¿å­˜å•å¸§æ·±åº¦
            np.save(frame_path, depths_array[i])
        
        print(f"  âœ… æ·±åº¦æ•°æ®æå–å®Œæˆ: {num_frames} ä¸ªæ–‡ä»¶")
        return num_frames
    
    def extract_pose_data(self, poses_array, target_file):
        """
        æå–ä½å§¿æ•°æ®
        ä» cam_c2w (N, 4, 4) â†’ stitched_predicted_poses.npz
        """
        os.makedirs(os.path.dirname(target_file), exist_ok=True)
        
        print(f"  ä¿å­˜ä½å§¿æ•°æ®: {poses_array.shape}")
        
        # ä¿å­˜ä¸ºè¯„ä¼°ä»£ç éœ€è¦çš„æ ¼å¼
        np.savez(target_file, data=poses_array)
        
        print(f"  âœ… ä½å§¿æ•°æ®ä¿å­˜å®Œæˆ: {poses_array.shape}")
        return poses_array.shape[0]
    
    def convert_single_file(self, filename, seq_name):
        """è½¬æ¢å•ä¸ªMegaSAMç»“æœæ–‡ä»¶"""
        print(f"\nğŸ”„ è½¬æ¢æ–‡ä»¶: {filename} â†’ {seq_name}")
        
        # è¾“å…¥æ–‡ä»¶è·¯å¾„
        input_file = os.path.join(self.megasam_input_dir, filename)
        
        # è¾“å‡ºè·¯å¾„
        target_seq_dir = os.path.join(self.output_base, seq_name)
        target_depth_dir = os.path.join(target_seq_dir, "combined_depth")
        target_pose_file = os.path.join(target_seq_dir, "stitched_predicted_poses.npz")
        
        try:
            # åŠ è½½MegaSAMæ•°æ®
            print("  ğŸ“‚ åŠ è½½MegaSAMç»“æœ...")
            data = np.load(input_file)
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            print(f"  æ•°æ®é”®: {list(data.keys())}")
            depths = data['depths']  # (N, H, W)
            poses = data['cam_c2w']  # (N, 4, 4)
            
            print(f"  æ·±åº¦å½¢çŠ¶: {depths.shape}")
            print(f"  ä½å§¿å½¢çŠ¶: {poses.shape}")
            
            # éªŒè¯å¸§æ•°ä¸€è‡´æ€§
            if depths.shape[0] != poses.shape[0]:
                raise ValueError(f"æ·±åº¦å¸§æ•°({depths.shape[0]}) != ä½å§¿å¸§æ•°({poses.shape[0]})")
            
            # æå–æ·±åº¦æ•°æ®
            print("  ğŸ“Š æå–æ·±åº¦æ•°æ®...")
            depth_count = self.extract_depth_data(depths, target_depth_dir)
            
            # æå–ä½å§¿æ•°æ®
            print("  ğŸ“ æå–ä½å§¿æ•°æ®...")
            pose_count = self.extract_pose_data(poses, target_pose_file)
            
            # éªŒè¯ç»“æœ
            if depth_count != pose_count:
                print(f"  âš ï¸  è­¦å‘Š: æ·±åº¦å¸§æ•°({depth_count}) != ä½å§¿å¸§æ•°({pose_count})")
            else:
                print(f"  âœ… å¸§æ•°ä¸€è‡´: {depth_count} å¸§")
            
            print(f"âœ… æ–‡ä»¶ {filename} è½¬æ¢å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶ {filename} è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def convert_all_files(self):
        """è½¬æ¢æ‰€æœ‰MegaSAMç»“æœæ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹è½¬æ¢MegaSAMç»“æœæ ¼å¼")
        print("=" * 80)
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not self.validate_input_files():
            return False
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_base, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_base}")
        
        # è½¬æ¢ç»Ÿè®¡
        successful = 0
        failed = 0
        
        # é€ä¸ªè½¬æ¢æ–‡ä»¶
        for filename, seq_name in self.file_mappings.items():
            if self.convert_single_file(filename, seq_name):
                successful += 1
            else:
                failed += 1
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 80)
        print("ğŸ‰ MegaSAMç»“æœæ ¼å¼è½¬æ¢å®Œæˆ")
        print("=" * 80)
        print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {len(self.file_mappings)}")
        print(f"  æˆåŠŸè½¬æ¢: {successful}")
        print(f"  è½¬æ¢å¤±è´¥: {failed}")
        print(f"  æˆåŠŸç‡: {successful/len(self.file_mappings):.1%}")
        
        if successful > 0:
            print(f"\nğŸ“ è½¬æ¢ç»“æœä¿å­˜åœ¨: {self.output_base}")
            print("ç°åœ¨å¯ä»¥ä½¿ç”¨è¯„ä¼°ä»£ç è¯„ä¼°MegaSAMçš„ç»“æœäº†ï¼")
        
        return successful == len(self.file_mappings)
    
    def list_converted_sequences(self):
        """åˆ—å‡ºå·²è½¬æ¢çš„åºåˆ—"""
        if not os.path.exists(self.output_base):
            print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œè½¬æ¢")
            return
        
        print(f"ğŸ“ å·²è½¬æ¢çš„åºåˆ— ({self.output_base}):")
        sequences = [d for d in os.listdir(self.output_base) 
                    if os.path.isdir(os.path.join(self.output_base, d))]
        
        for seq in sorted(sequences):
            seq_dir = os.path.join(self.output_base, seq)
            depth_dir = os.path.join(seq_dir, "combined_depth")
            pose_file = os.path.join(seq_dir, "stitched_predicted_poses.npz")
            
            depth_count = len([f for f in os.listdir(depth_dir) if f.endswith('.npy')]) if os.path.exists(depth_dir) else 0
            pose_exists = os.path.exists(pose_file)
            
            status = "âœ…" if depth_count > 0 and pose_exists else "âŒ"
            print(f"  {status} {seq}: {depth_count} æ·±åº¦æ–‡ä»¶, ä½å§¿æ–‡ä»¶ {'å­˜åœ¨' if pose_exists else 'ç¼ºå¤±'}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='MegaSAMç»“æœæ ¼å¼è½¬æ¢å·¥å…·')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºå·²è½¬æ¢çš„åºåˆ—')
    parser.add_argument('--file', type=str, help='åªè½¬æ¢æŒ‡å®šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    converter = MegaSAMResultConverter()
    
    if args.list:
        converter.list_converted_sequences()
    elif args.file:
        # è½¬æ¢å•ä¸ªæ–‡ä»¶
        if args.file not in converter.file_mappings:
            print(f"âŒ æ–‡ä»¶ '{args.file}' ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")
            print(f"æ”¯æŒçš„æ–‡ä»¶: {list(converter.file_mappings.keys())}")
            return
        
        seq_name = converter.file_mappings[args.file]
        success = converter.convert_single_file(args.file, seq_name)
        print(f"{'âœ…' if success else 'âŒ'} æ–‡ä»¶ {args.file} è½¬æ¢{'æˆåŠŸ' if success else 'å¤±è´¥'}")
    else:
        # è½¬æ¢æ‰€æœ‰æ–‡ä»¶
        converter.convert_all_files()


if __name__ == "__main__":
    main()
