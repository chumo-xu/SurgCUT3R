#!/usr/bin/env python3
"""
Spann3Rç»“æœæ ¼å¼è½¬æ¢è„šæœ¬
å°†Spann3Rçš„æ·±åº¦å’Œä½å§¿ç»“æœè½¬æ¢ä¸ºCUT3Rè¯„ä¼°ä»£ç éœ€è¦çš„æ ¼å¼
"""

import os
import numpy as np
from pathlib import Path
from tqdm import tqdm


class Spann3RResultConverter:
    """Spann3Rç»“æœè½¬æ¢å™¨"""
    
    def __init__(self):
        # è¾“å…¥è·¯å¾„
        self.spann3r_input_dir = "/hy-tmp/hy-tmp/CUT3R/eval/spann3r/hy-tmp/output"
        
        # è¾“å‡ºè·¯å¾„
        self.output_base = "/hy-tmp/hy-tmp/CUT3R/eval/spann3r/spann3r_results"
        
        # ç›®å½•ååˆ°åºåˆ—åçš„æ˜ å°„
        self.sequence_mappings = {
            "Scared8_0_Left_Images": "dual_evaluation_dataset8_keyframe0",
            "Scared8_1_Left_Images": "dual_evaluation_dataset8_keyframe1",
            "Scared8_2_Left_Images": "dual_evaluation_dataset8_keyframe2", 
            "Scared8_3_Left_Images": "dual_evaluation_dataset8_keyframe3",
            "Scared9_0_Left_Images": "dual_evaluation_dataset9_keyframe0",
            "Scared9_1_Left_Images": "dual_evaluation_dataset9_keyframe1",
            "Scared9_2_Left_Images": "dual_evaluation_dataset9_keyframe2",
            "Scared9_3_Left_Images": "dual_evaluation_dataset9_keyframe3",
        }
    
    def validate_input_files(self):
        """éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("ğŸ” éªŒè¯è¾“å…¥æ–‡ä»¶...")
        
        missing_files = []
        
        for dirname in self.sequence_mappings.keys():
            # spann3rçš„æ–‡ä»¶è·¯å¾„æ ¼å¼ï¼šdirname/dirname/dirname.npy
            file_path = os.path.join(self.spann3r_input_dir, dirname, dirname, f"{dirname}.npy")
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            print("âŒ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶:")
            for filepath in missing_files:
                print(f"   {filepath}")
            return False
        
        print("âœ… æ‰€æœ‰è¾“å…¥æ–‡ä»¶éªŒè¯æˆåŠŸ")
        return True
    
    def extract_depth_data(self, pts_all, target_dir):
        """
        ä»3Dç‚¹äº‘æ•°æ®ä¸­æå–æ·±åº¦ä¿¡æ¯
        ä» pts_all[:, :, :, 2] â†’ 000000.npy, 000001.npy, ...
        """
        os.makedirs(target_dir, exist_ok=True)
        
        # æå–æ·±åº¦æ•°æ®ï¼ˆZåæ ‡ï¼‰
        depth_data = pts_all[:, :, :, 2]  # (N, H, W)
        num_frames = depth_data.shape[0]
        
        print(f"  æå– {num_frames} å¸§æ·±åº¦æ•°æ®...")
        print(f"  æ·±åº¦åˆ†è¾¨ç‡: {depth_data.shape[1]}x{depth_data.shape[2]}")
        
        for i in tqdm(range(num_frames), desc="  æ·±åº¦å¸§"):
            # æ ¼å¼åŒ–å¸§å·ä¸º6ä½æ•°å­—
            frame_filename = f"{i:06d}.npy"
            frame_path = os.path.join(target_dir, frame_filename)
            
            # ä¿å­˜å•å¸§æ·±åº¦
            np.save(frame_path, depth_data[i])
        
        print(f"  âœ… æ·±åº¦æ•°æ®æå–å®Œæˆ: {num_frames} ä¸ªæ–‡ä»¶")
        return num_frames
    
    def extract_pose_data(self, poses_all, target_file):
        """
        æå–ä½å§¿æ•°æ®
        poses_all å·²ç»æ˜¯ (N, 4, 4) æ ¼å¼ï¼Œç›´æ¥ä¿å­˜
        """
        os.makedirs(os.path.dirname(target_file), exist_ok=True)
        
        print(f"  ä¿å­˜ä½å§¿æ•°æ®: {poses_all.shape}")
        
        # ä¿å­˜ä¸ºè¯„ä¼°ä»£ç éœ€è¦çš„æ ¼å¼
        np.savez(target_file, data=poses_all)
        
        print(f"  âœ… ä½å§¿æ•°æ®ä¿å­˜å®Œæˆ: {poses_all.shape}")
        return poses_all.shape[0]
    
    def convert_single_sequence(self, dirname, seq_name):
        """è½¬æ¢å•ä¸ªåºåˆ—"""
        print(f"\nğŸ”„ è½¬æ¢åºåˆ—: {dirname} â†’ {seq_name}")
        
        # è¾“å…¥æ–‡ä»¶è·¯å¾„
        input_file = os.path.join(self.spann3r_input_dir, dirname, dirname, f"{dirname}.npy")
        
        # è¾“å‡ºè·¯å¾„
        target_seq_dir = os.path.join(self.output_base, seq_name)
        target_depth_dir = os.path.join(target_seq_dir, "combined_depth")
        target_pose_file = os.path.join(target_seq_dir, "stitched_predicted_poses.npz")
        
        try:
            # åŠ è½½Spann3Ræ•°æ®
            print("  ğŸ“‚ åŠ è½½Spann3Rç»“æœ...")
            data = np.load(input_file, allow_pickle=True).item()
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            required_keys = ['pts_all', 'poses_all']
            for key in required_keys:
                if key not in data:
                    raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„æ•°æ®é”®: {key}")
            
            pts_all = data['pts_all']      # (N, H, W, 3)
            poses_all = data['poses_all']  # (N, 4, 4)
            
            print(f"  3Dç‚¹äº‘å½¢çŠ¶: {pts_all.shape}")
            print(f"  ä½å§¿å½¢çŠ¶: {poses_all.shape}")
            
            # éªŒè¯å¸§æ•°ä¸€è‡´æ€§
            if pts_all.shape[0] != poses_all.shape[0]:
                raise ValueError(f"ç‚¹äº‘å¸§æ•°({pts_all.shape[0]}) != ä½å§¿å¸§æ•°({poses_all.shape[0]})")
            
            # æå–æ·±åº¦æ•°æ®
            print("  ğŸ“Š æå–æ·±åº¦æ•°æ®...")
            depth_count = self.extract_depth_data(pts_all, target_depth_dir)
            
            # æå–ä½å§¿æ•°æ®
            print("  ğŸ“ æå–ä½å§¿æ•°æ®...")
            pose_count = self.extract_pose_data(poses_all, target_pose_file)
            
            # éªŒè¯ç»“æœ
            if depth_count != pose_count:
                print(f"  âš ï¸  è­¦å‘Š: æ·±åº¦å¸§æ•°({depth_count}) != ä½å§¿å¸§æ•°({pose_count})")
            else:
                print(f"  âœ… å¸§æ•°ä¸€è‡´: {depth_count} å¸§")
            
            print(f"âœ… åºåˆ— {dirname} è½¬æ¢å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ åºåˆ— {dirname} è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def convert_all_sequences(self):
        """è½¬æ¢æ‰€æœ‰Spann3Rç»“æœåºåˆ—"""
        print("ğŸš€ å¼€å§‹è½¬æ¢Spann3Rç»“æœæ ¼å¼")
        print("=" * 80)
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not self.validate_input_files():
            return False
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_base, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_base}")
        
        # è½¬æ¢ç»Ÿè®¡
        successful = 0
        failed = 0
        
        # é€ä¸ªè½¬æ¢åºåˆ—
        for dirname, seq_name in self.sequence_mappings.items():
            if self.convert_single_sequence(dirname, seq_name):
                successful += 1
            else:
                failed += 1
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 80)
        print("ğŸ‰ Spann3Rç»“æœæ ¼å¼è½¬æ¢å®Œæˆ")
        print("=" * 80)
        print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡:")
        print(f"  æ€»åºåˆ—æ•°: {len(self.sequence_mappings)}")
        print(f"  æˆåŠŸè½¬æ¢: {successful}")
        print(f"  è½¬æ¢å¤±è´¥: {failed}")
        print(f"  æˆåŠŸç‡: {successful/len(self.sequence_mappings):.1%}")
        
        if successful > 0:
            print(f"\nğŸ“ è½¬æ¢ç»“æœä¿å­˜åœ¨: {self.output_base}")
            print("ç°åœ¨å¯ä»¥ä½¿ç”¨è¯„ä¼°ä»£ç è¯„ä¼°Spann3Rçš„ç»“æœäº†ï¼")
        
        return successful == len(self.sequence_mappings)
    
    def list_converted_sequences(self):
        """åˆ—å‡ºå·²è½¬æ¢çš„åºåˆ—"""
        if not os.path.exists(self.output_base):
            print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œè½¬æ¢")
            return
        
        print(f"ğŸ“ å·²è½¬æ¢çš„åºåˆ— ({self.output_base}):")
        sequences = [d for d in os.listdir(self.output_base) 
                    if os.path.isdir(os.path.join(self.output_base, d))]
        
        for seq in sorted(sequences):
            seq_dir = os.path.join(self.output_base, seq)
            depth_dir = os.path.join(seq_dir, "combined_depth")
            pose_file = os.path.join(seq_dir, "stitched_predicted_poses.npz")
            
            depth_count = len([f for f in os.listdir(depth_dir) if f.endswith('.npy')]) if os.path.exists(depth_dir) else 0
            pose_exists = os.path.exists(pose_file)
            
            status = "âœ…" if depth_count > 0 and pose_exists else "âŒ"
            print(f"  {status} {seq}: {depth_count} æ·±åº¦æ–‡ä»¶, ä½å§¿æ–‡ä»¶ {'å­˜åœ¨' if pose_exists else 'ç¼ºå¤±'}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Spann3Rç»“æœæ ¼å¼è½¬æ¢å·¥å…·')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºå·²è½¬æ¢çš„åºåˆ—')
    parser.add_argument('--sequence', type=str, help='åªè½¬æ¢æŒ‡å®šåºåˆ—ç›®å½•')
    
    args = parser.parse_args()
    
    converter = Spann3RResultConverter()
    
    if args.list:
        converter.list_converted_sequences()
    elif args.sequence:
        # è½¬æ¢å•ä¸ªåºåˆ—
        if args.sequence not in converter.sequence_mappings:
            print(f"âŒ åºåˆ— '{args.sequence}' ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")
            print(f"æ”¯æŒçš„åºåˆ—: {list(converter.sequence_mappings.keys())}")
            return
        
        seq_name = converter.sequence_mappings[args.sequence]
        success = converter.convert_single_sequence(args.sequence, seq_name)
        print(f"{'âœ…' if success else 'âŒ'} åºåˆ— {args.sequence} è½¬æ¢{'æˆåŠŸ' if success else 'å¤±è´¥'}")
    else:
        # è½¬æ¢æ‰€æœ‰åºåˆ—
        converter.convert_all_sequences()


if __name__ == "__main__":
    main()
