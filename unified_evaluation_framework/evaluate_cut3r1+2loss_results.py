#!/usr/bin/env python3
"""
CUT3Rç»“æœè¯„ä¼°è„šæœ¬
ä½¿ç”¨ç»Ÿä¸€è¯„ä¼°æ¡†æ¶è¯„ä¼°CUT3Rçš„æ¨ç†ç»“æœ
"""

import os
import sys
import numpy as np
import json
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ æ¡†æ¶è·¯å¾„
framework_dir = Path(__file__).parent
sys.path.insert(0, str(framework_dir))

from evaluators.unified_evaluator import UnifiedEvaluator


class CUT3RResultsEvaluator:
    """CUT3Rç»“æœè¯„ä¼°å™¨"""
    
    def __init__(self, verbose=True):
        """
        åˆå§‹åŒ–CUT3Rç»“æœè¯„ä¼°å™¨
        
        Args:
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        
        # CUT3Rç»“æœè·¯å¾„
        self.results_base = "/hy-tmp/hy-tmp/CUT3R/eval/cut3r+loss"
        self.gt_base = "/hy-tmp/hy-tmp/CUT3R/eval/eval_data/test"
        
        # åºåˆ—åˆ—è¡¨
        self.sequences = [
            "dual_evaluation_dataset8_keyframe0",
            "dual_evaluation_dataset8_keyframe1", 
            "dual_evaluation_dataset8_keyframe2",
            "dual_evaluation_dataset8_keyframe3",
            "dual_evaluation_dataset9_keyframe0",
            "dual_evaluation_dataset9_keyframe1",
            "dual_evaluation_dataset9_keyframe2",
            "dual_evaluation_dataset9_keyframe3"
        ]
        
        # åˆå§‹åŒ–ç»Ÿä¸€è¯„ä¼°å™¨
        self.evaluator = UnifiedEvaluator(
            depth_min=1e-3,      # æœ€å°æ·±åº¦ 1mm
            depth_max=150.0,     # æœ€å¤§æ·±åº¦ 150m 
            pose_window_size=16, # L-ATEçª—å£å¤§å°
            verbose=verbose
        )
        
        if verbose:
            print("ğŸš€ CUT3Rç»“æœè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"è¯„ä¼°åºåˆ—æ•°: {len(self.sequences)}")
    
    def get_sequence_paths(self, sequence_name):
        """
        è·å–å•ä¸ªåºåˆ—çš„æ‰€æœ‰è·¯å¾„
        
        Args:
            sequence_name: åºåˆ—åç§°ï¼Œå¦‚ "dual_evaluation_dataset8_keyframe0"
        
        Returns:
            dict: åŒ…å«æ‰€æœ‰è·¯å¾„çš„å­—å…¸
        """
        # --- ä¸ºæµ‹è¯•åºåˆ—æ·»åŠ çš„ä¸´æ—¶ä¿®æ”¹ ---
        if sequence_name == "dual_evaluation_dataset9_keyframe3test":
            dataset_num = '9'
            keyframe_num = '3' # ä½¿ç”¨åŸå§‹keyframe3çš„çœŸå€¼è¿›è¡Œæ¯”è¾ƒ
            paths = {
                'sequence_name': sequence_name,
                'dataset_num': dataset_num,
                'keyframe_num': keyframe_num,
                
                # é¢„æµ‹ç»“æœè·¯å¾„ (æ¥è‡ªç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•æ–‡ä»¶å¤¹)
                'pred_pose_file': f"/hy-tmp/hy-tmp/CUT3R/eval/test_all_sequences/{sequence_name}/cut3r1+cut3r2.npz",
                
                # GTæ•°æ®è·¯å¾„ (ä½¿ç”¨ keyframe3 çš„çœŸå€¼) 
                'gt_pose_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_absolute_poses_{dataset_num}_{keyframe_num}_c2w.npz",
                
                # è¾“å‡ºè·¯å¾„
                'output_dir': f"{self.results_base}/{sequence_name}/unified_evaluation_results_pose_only"
            }
            return paths
        # --- ä¸´æ—¶ä¿®æ”¹ç»“æŸ ---

        # è§£æåºåˆ—åç§°
        # dual_evaluation_dataset8_keyframe0 -> dataset8, keyframe0
        parts = sequence_name.split('_')
        dataset = parts[2]  # dataset8
        keyframe = parts[3] # keyframe0
        
        # æå–æ•°å­—
        dataset_num = dataset.replace('dataset', '')  # 8
        keyframe_num = keyframe.replace('keyframe', '') # 0
        
        paths = {
            'sequence_name': sequence_name,
            'dataset_num': dataset_num,
            'keyframe_num': keyframe_num,
            
            # é¢„æµ‹ç»“æœè·¯å¾„
            'pred_pose_file': f"/hy-tmp/hy-tmp/CUT3R/eval/test_all_sequences/{sequence_name}/cut3r1+cut3r2.npz",
            
            # GTæ•°æ®è·¯å¾„  
            'gt_pose_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_absolute_poses_{dataset_num}_{keyframe_num}_c2w.npz",
            
            # è¾“å‡ºè·¯å¾„
            'output_dir': f"{self.results_base}/{sequence_name}/unified_evaluation_results_pose_only"
        }
        
        return paths
    
    def validate_sequence_paths(self, paths):
        """
        éªŒè¯åºåˆ—è·¯å¾„æ˜¯å¦å­˜åœ¨
        """
        required_paths = [
            ('pred_pose_file', paths['pred_pose_file']),
            ('gt_pose_file', paths['gt_pose_file'])
        ]
        
        missing_paths = []
        for name, path in required_paths:
            if not os.path.exists(path):
                missing_paths.append((name, path))
        
        if missing_paths:
            print(f"âŒ åºåˆ— {paths['sequence_name']} ç¼ºå°‘è·¯å¾„:")
            for name, path in missing_paths:
                print(f"   {name}: {path}")
            return False
        
        return True
    
    def evaluate_single_sequence(self, sequence_name):
        """
        è¯„ä¼°å•ä¸ªåºåˆ—
        
        Args:
            sequence_name: åºåˆ—åç§°
            
        Returns:
            dict: è¯„ä¼°ç»“æœï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if self.verbose:
            print(f"\nğŸ” è¯„ä¼°åºåˆ—: {sequence_name}")
        
        # è·å–è·¯å¾„
        paths = self.get_sequence_paths(sequence_name)
        
        # éªŒè¯è·¯å¾„
        if not self.validate_sequence_paths(paths):
            return None
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€è¯„ä¼°æ¡†æ¶è¿›è¡Œè¯„ä¼°
            pose_results = self.evaluator.evaluate_pose_only(
                gt_pose_path=paths['gt_pose_file'],
                pred_pose_path=paths['pred_pose_file'],
                output_dir=paths['output_dir'],
                # ä½å§¿é…ç½®
                gt_pose_format='npz_file',       # GTæ˜¯NPZæ–‡ä»¶
                pred_pose_format='npz_file',     # <--- å…³é”®ä¿®æ­£ï¼šæ˜¾å¼æŒ‡å®šé¢„æµ‹ä½å§¿ä¸ºå•ä¸ªæ–‡ä»¶
                gt_pose_unit='m',                # ç¡®è®¤å•ä½: ä½å§¿ä½ç§»ç»Ÿä¸€ä¸ºç±³
                pred_pose_unit='m',              # ç¡®è®¤å•ä½: ä½å§¿ä½ç§»ç»Ÿä¸€ä¸ºç±³
                # å¯è§†åŒ–é…ç½®
                sequence_name=sequence_name
            )

            # å°† `evaluate_pose_only` çš„ç›´æ¥ç»“æœåŒ…è£…æˆæŠ¥å‘Šå‡½æ•°æœŸæœ›çš„ç»“æ„
            results = {'pose_evaluation': pose_results}
            
            if self.verbose:
                print(f"âœ… åºåˆ— {sequence_name} è¯„ä¼°æˆåŠŸ")
            
            return results
            
        except Exception as e:
            print(f"âŒ åºåˆ— {sequence_name} è¯„ä¼°å¤±è´¥: {e}")
            if self.verbose:
                import traceback
                traceback.print_exc()
            return None
    
    def evaluate_all_sequences(self, output_summary_dir=None):
        """
        è¯„ä¼°æ‰€æœ‰åºåˆ—
        
        Args:
            output_summary_dir: æ€»ç»“æœè¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
        
        Returns:
            dict: æ‰€æœ‰åºåˆ—çš„è¯„ä¼°ç»“æœ
        """
        if output_summary_dir is None:
            output_summary_dir = f"{self.results_base}/unified_evaluation_summary"
        
        os.makedirs(output_summary_dir, exist_ok=True)
        
        print("ğŸš€ å¼€å§‹è¯„ä¼°æ‰€æœ‰CUT3Råºåˆ—")
        print("=" * 70)
        
        all_results = {}
        successful_sequences = []
        failed_sequences = []
        
        # é€ä¸ªåºåˆ—è¯„ä¼°
        for sequence_name in tqdm(self.sequences, desc="è¯„ä¼°åºåˆ—"):
            result = self.evaluate_single_sequence(sequence_name)
            
            if result is not None:
                all_results[sequence_name] = result
                successful_sequences.append(sequence_name)
            else:
                failed_sequences.append(sequence_name)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        summary = self._generate_summary_report(all_results, successful_sequences, failed_sequences)
        
        # ä¿å­˜æ€»ç»“æœ
        summary_file = os.path.join(output_summary_dir, 'cut3r_evaluation_summary.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = os.path.join(output_summary_dir, 'cut3r_evaluation_report.txt')
        self._save_detailed_report(summary, report_file)
        
        # æ‰“å°æ€»ç»“
        self._print_summary(summary)
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_summary_dir}")
        
        return all_results
    
    def _generate_summary_report(self, all_results, successful_sequences, failed_sequences):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        gate_rmses = []
        late_rmse_means = []
        late_rmse_stds = []
        
        for seq_name, result in all_results.items():
            pose_eval = result['pose_evaluation']['pose_metrics']
            
            gate_rmses.append(pose_eval['gate']['gate_rmse'])
            late_rmse_means.append(pose_eval['late']['late_rmse_mean'])
            late_rmse_stds.append(pose_eval['late']['late_rmse_std'])
        
        if len(gate_rmses) > 0:
            avg_pose_metrics = {
                'gate_rmse': np.mean(gate_rmses),
                'late_rmse_mean': np.mean(late_rmse_means),
                'late_rmse_std': np.mean(late_rmse_stds)
            }
        else:
            avg_pose_metrics = {}
        
        summary = {
            'evaluation_info': {
                'total_sequences': len(self.sequences),
                'successful_sequences': len(successful_sequences),
                'failed_sequences': len(failed_sequences),
                'success_rate': len(successful_sequences) / len(self.sequences) if len(self.sequences) > 0 else 0
            },
            'successful_sequences': successful_sequences,
            'failed_sequences': failed_sequences,
            'average_metrics': {
                'pose': avg_pose_metrics
            },
            'per_sequence_metrics': {
                'pose': {
                    'gate_rmses': gate_rmses,
                    'late_rmse_means': late_rmse_means,
                    'late_rmse_stds': late_rmse_stds
                }
            }
        }
        
        return summary
    
    def _save_detailed_report(self, summary, report_file):
        """ä¿å­˜è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š"""
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CUT3Ræ¨¡å‹è¯„ä¼°æŠ¥å‘Š - ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ (ä»…ä½å§¿)\n")
            f.write("=" * 80 + "\n\n")
            
            info = summary['evaluation_info']
            f.write(f"è¯„ä¼°åºåˆ—æ€»æ•°: {info['total_sequences']}\n")
            f.write(f"æˆåŠŸè¯„ä¼°: {info['successful_sequences']}\n")
            f.write(f"å¤±è´¥è¯„ä¼°: {info['failed_sequences']}\n")
            f.write(f"æˆåŠŸç‡: {info['success_rate']:.1%}\n\n")
            
            if info['failed_sequences'] > 0:
                f.write("å¤±è´¥åºåˆ—:\n")
                for seq in summary['failed_sequences']:
                    f.write(f"  - {seq}\n")
                f.write("\n")
            
            if summary['average_metrics']['pose']:
                pose_avg = summary['average_metrics']['pose']
                
                f.write("ğŸ¯ å¹³å‡è¯„ä¼°ç»“æœ:\n")
                f.write("-" * 50 + "\n")
                f.write("ä½å§¿æŒ‡æ ‡:\n")
                f.write(f"  G-ATE RMSE: {pose_avg['gate_rmse']:.4f} m\n")
                f.write(f"  L-ATE RMSE: {pose_avg['late_rmse_mean']:.4f} Â± {pose_avg['late_rmse_std']:.4f} m\n\n")
            
            f.write("ğŸ“Š å„åºåˆ—è¯¦ç»†ç»“æœ:\n")
            f.write("-" * 50 + "\n")
            for i, seq in enumerate(summary['successful_sequences']):
                f.write(f"{seq}:\n")
                gate_rmse = summary['per_sequence_metrics']['pose']['gate_rmses'][i]
                late_mean = summary['per_sequence_metrics']['pose']['late_rmse_means'][i]
                late_std = summary['per_sequence_metrics']['pose']['late_rmse_stds'][i]
                f.write(f"  ä½å§¿: G-ATE={gate_rmse:.4f}m, L-ATE={late_mean:.4f}Â±{late_std:.4f}m\n\n")
    
    def _print_summary(self, summary):
        """æ‰“å°è¯„ä¼°æ€»ç»“"""
        print("\n" + "=" * 80)
        print("ğŸ‰ CUT3Ræ¨¡å‹è¯„ä¼°å®Œæˆ - æ€»ç»“æŠ¥å‘Š (ä»…ä½å§¿)")
        print("=" * 80)
        
        info = summary['evaluation_info']
        print(f"ğŸ“Š è¯„ä¼°ç»Ÿè®¡:")
        print(f"  æ€»åºåˆ—æ•°: {info['total_sequences']}")
        print(f"  æˆåŠŸè¯„ä¼°: {info['successful_sequences']}")
        print(f"  æˆåŠŸç‡: {info['success_rate']:.1%}")
        
        if info['failed_sequences'] > 0:
            print(f"  å¤±è´¥åºåˆ—: {summary['failed_sequences']}")
        
        if summary['average_metrics']['pose']:
            pose_avg = summary['average_metrics']['pose']
            
            print(f"\nğŸ¯ å¹³å‡æ€§èƒ½æŒ‡æ ‡:")
            print(f"  ä½å§¿ä¼°è®¡:")
            print(f"    G-ATE:    {pose_avg['gate_rmse']:.4f} m")
            print(f"    L-ATE:    {pose_avg['late_rmse_mean']:.4f} Â± {pose_avg['late_rmse_std']:.4f} m")
            
            print(f"\nğŸ† æ€§èƒ½è¯„çº§:")
            if pose_avg['gate_rmse'] < 0.01 and pose_avg['late_rmse_mean'] < 0.01:
                pose_grade = "ä¼˜ç§€ (Sçº§)"
            elif pose_avg['gate_rmse'] < 0.05 and pose_avg['late_rmse_mean'] < 0.05:
                pose_grade = "è‰¯å¥½ (Açº§)"
            else:
                pose_grade = "æœ‰å¾…æ”¹è¿› (Bçº§)"
            print(f"  ä½å§¿ä¼°è®¡: {pose_grade}")
        
        print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CUT3Rç»“æœè¯„ä¼°å·¥å…·')
    parser.add_argument('--sequence', type=str, help='è¯„ä¼°ç‰¹å®šåºåˆ—ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è¯„ä¼°æ‰€æœ‰åºåˆ—')
    parser.add_argument('--output', type=str, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = CUT3RResultsEvaluator(verbose=args.verbose)
    
    if args.sequence:
        # è¯„ä¼°å•ä¸ªåºåˆ—
        if args.sequence not in evaluator.sequences:
            print(f"âŒ åºåˆ— '{args.sequence}' ä¸åœ¨æ”¯æŒçš„åºåˆ—åˆ—è¡¨ä¸­")
            print(f"æ”¯æŒçš„åºåˆ—: {evaluator.sequences}")
            return
        
        result = evaluator.evaluate_single_sequence(args.sequence)
        if result:
            print(f"âœ… åºåˆ— {args.sequence} è¯„ä¼°å®Œæˆ")
            # æ‰“å°ç®€è¦ç»“æœ
            evaluator.evaluator.print_complete_results(result)
    else:
        # è¯„ä¼°æ‰€æœ‰åºåˆ—
        all_results = evaluator.evaluate_all_sequences(args.output)
        print(f"âœ… æ‰€æœ‰åºåˆ—è¯„ä¼°å®Œæˆï¼ŒæˆåŠŸè¯„ä¼° {len(all_results)} ä¸ªåºåˆ—")


if __name__ == "__main__":
    main()
