#!/usr/bin/env python3
"""
CUT3Rç»“æžœè¯„ä¼°è„šæœ¬
ä½¿ç”¨ç»Ÿä¸€è¯„ä¼°æ¡†æž¶è¯„ä¼°CUT3Rçš„æŽ¨ç†ç»“æžœ
"""

import os
import sys
import numpy as np
import json
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ æ¡†æž¶è·¯å¾„
framework_dir = Path(__file__).parent
sys.path.insert(0, str(framework_dir))

from evaluators.unified_evaluator import UnifiedEvaluator


class CUT3RResultsEvaluator:
    """CUT3Rç»“æžœè¯„ä¼°å™¨"""
    
    def __init__(self, verbose=True):
        """
        åˆå§‹åŒ–CUT3Rç»“æžœè¯„ä¼°å™¨
        
        Args:
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        
        # CUT3Rç»“æžœè·¯å¾„
        self.results_base = "/hy-tmp/hy-tmp/CUT3R/eval/cut3r_inference_results copy_code_test"
        self.gt_base = "/hy-tmp/hy-tmp/CUT3R/eval/eval_data/test"
        
        # åºåˆ—åˆ—è¡¨
        self.sequences = [
            "dual_evaluation_dataset8_keyframe0",
            "dual_evaluation_dataset8_keyframe1", 
            "dual_evaluation_dataset8_keyframe2",
            "dual_evaluation_dataset8_keyframe3",
            "dual_evaluation_dataset9_keyframe0",
            "dual_evaluation_dataset9_keyframe1",
            "dual_evaluation_dataset9_keyframe2",
            "dual_evaluation_dataset9_keyframe3",
            "dual_evaluation_dataset9_keyframe3test"
        ]
        
        # åˆå§‹åŒ–ç»Ÿä¸€è¯„ä¼°å™¨
        self.evaluator = UnifiedEvaluator(
            depth_min=1e-3,      # æœ€å°æ·±åº¦ 1mm
            depth_max=150.0,     # æœ€å¤§æ·±åº¦ 150m 
            pose_window_size=16, # L-ATEçª—å£å¤§å°
            verbose=verbose
        )
        
        if verbose:
            print("ðŸš€ CUT3Rç»“æžœè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"è¯„ä¼°åºåˆ—æ•°: {len(self.sequences)}")
    
    def get_sequence_paths(self, sequence_name):
        """
        èŽ·å–å•ä¸ªåºåˆ—çš„æ‰€æœ‰è·¯å¾„
        
        Args:
            sequence_name: åºåˆ—åç§°ï¼Œå¦‚ "dual_evaluation_dataset8_keyframe0"
        
        Returns:
            dict: åŒ…å«æ‰€æœ‰è·¯å¾„çš„å­—å…¸
        """
        # --- ä¸ºæµ‹è¯•åºåˆ—æ·»åŠ çš„ä¸´æ—¶ä¿®æ”¹ ---
        if sequence_name == "dual_evaluation_dataset9_keyframe3test":
            dataset_num = '9'
            keyframe_num = '3' # ä½¿ç”¨åŽŸå§‹keyframe3çš„çœŸå€¼è¿›è¡Œæ¯”è¾ƒ
            paths = {
                'sequence_name': sequence_name,
                'dataset_num': dataset_num,
                'keyframe_num': keyframe_num,
                
                # é¢„æµ‹ç»“æžœè·¯å¾„ (æ¥è‡ªç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•æ–‡ä»¶å¤¹)
                'pred_depth_dir': f"{self.results_base}/{sequence_name}/combined_depth",
                'pred_pose_file': f"{self.results_base}/{sequence_name}/stitched_predicted_poses.npz",
                
                # GTæ•°æ®è·¯å¾„ (ä½¿ç”¨ keyframe3 çš„çœŸå€¼) 
                'gt_depth_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_depths_{dataset_num}_{keyframe_num}.npz",
                'gt_pose_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_absolute_poses_{dataset_num}_{keyframe_num}_c2w.npz",
                
                # è¾“å‡ºè·¯å¾„
                'output_dir': f"{self.results_base}/{sequence_name}/unified_evaluation_results"
            }
            return paths
        # --- ä¸´æ—¶ä¿®æ”¹ç»“æŸ ---

        # è§£æžåºåˆ—åç§°
        # dual_evaluation_dataset8_keyframe0 -> dataset8, keyframe0
        parts = sequence_name.split('_')
        dataset = parts[2]  # dataset8
        keyframe = parts[3] # keyframe0
        
        # æå–æ•°å­—
        dataset_num = dataset.replace('dataset', '')  # 8
        keyframe_num = keyframe.replace('keyframe', '') # 0
        
        paths = {
            'sequence_name': sequence_name,
            'dataset_num': dataset_num,
            'keyframe_num': keyframe_num,
            
            # é¢„æµ‹ç»“æžœè·¯å¾„
            'pred_depth_dir': f"{self.results_base}/{sequence_name}/combined_depth",
            'pred_pose_file': f"{self.results_base}/{sequence_name}/stitched_predicted_poses.npz",
            
            # GTæ•°æ®è·¯å¾„  
            'gt_depth_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_depths_{dataset_num}_{keyframe_num}.npz",
            'gt_pose_file': f"{self.gt_base}/dataset{dataset_num}/keyframe{keyframe_num}/gt_absolute_poses_{dataset_num}_{keyframe_num}_c2w.npz",
            
            # è¾“å‡ºè·¯å¾„
            'output_dir': f"{self.results_base}/{sequence_name}/unified_evaluation_results"
        }
        
        return paths
    
    def validate_sequence_paths(self, paths):
        """
        éªŒè¯åºåˆ—è·¯å¾„æ˜¯å¦å­˜åœ¨
        
        Args:
            paths: è·¯å¾„å­—å…¸
            
        Returns:
            bool: æ˜¯å¦æ‰€æœ‰è·¯å¾„éƒ½å­˜åœ¨
        """
        required_paths = [
            ('pred_depth_dir', paths['pred_depth_dir']),
            ('pred_pose_file', paths['pred_pose_file']),
            ('gt_depth_file', paths['gt_depth_file']),
            ('gt_pose_file', paths['gt_pose_file'])
        ]
        
        missing_paths = []
        for name, path in required_paths:
            if not os.path.exists(path):
                missing_paths.append((name, path))
        
        if missing_paths:
            print(f"âŒ åºåˆ— {paths['sequence_name']} ç¼ºå°‘è·¯å¾„:")
            for name, path in missing_paths:
                print(f"   {name}: {path}")
            return False
        
        return True
    
    def evaluate_single_sequence(self, sequence_name):
        """
        è¯„ä¼°å•ä¸ªåºåˆ—
        
        Args:
            sequence_name: åºåˆ—åç§°
            
        Returns:
            dict: è¯„ä¼°ç»“æžœï¼Œå¦‚æžœå¤±è´¥è¿”å›žNone
        """
        if self.verbose:
            print(f"\nðŸ” è¯„ä¼°åºåˆ—: {sequence_name}")
        
        # èŽ·å–è·¯å¾„
        paths = self.get_sequence_paths(sequence_name)
        
        # éªŒè¯è·¯å¾„
        if not self.validate_sequence_paths(paths):
            return None
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€è¯„ä¼°æ¡†æž¶è¿›è¡Œè¯„ä¼°
            results = self.evaluator.evaluate_complete(
                gt_depth_path=paths['gt_depth_file'],
                pred_depth_path=paths['pred_depth_dir'],
                gt_pose_path=paths['gt_pose_file'],
                pred_pose_path=paths['pred_pose_file'],
                output_dir=paths['output_dir'],
                # æ·±åº¦é…ç½®
                gt_depth_format='npz_file',      # GTæ˜¯NPZæ–‡ä»¶
                pred_depth_format='npy_dir',     # é¢„æµ‹æ˜¯NPYç›®å½•
                gt_depth_unit='m',               # ç¡®è®¤å•ä½: æ·±åº¦æ•°æ®ç»Ÿä¸€ä¸ºç±³
                pred_depth_unit='m',             # ç¡®è®¤å•ä½: æ·±åº¦æ•°æ®ç»Ÿä¸€ä¸ºç±³
                # ä½å§¿é…ç½®
                gt_pose_format='npz_file',       # GTæ˜¯NPZæ–‡ä»¶
                pred_pose_format='npz_file',     # é¢„æµ‹æ˜¯NPZæ–‡ä»¶
                gt_pose_unit='m',                # ç¡®è®¤å•ä½: ä½å§¿ä½ç§»ç»Ÿä¸€ä¸ºç±³
                pred_pose_unit='m',              # ç¡®è®¤å•ä½: ä½å§¿ä½ç§»ç»Ÿä¸€ä¸ºç±³
                # è¯„ä¼°é…ç½®
                depth_mode='both',               # ä½¿ç”¨åŒé‡æ·±åº¦è¯„ä¼°æ–¹æ³•ï¼ˆå…¨å±€+åˆ†æ®µï¼‰
                # å¯è§†åŒ–é…ç½®
                sequence_name=sequence_name
            )
            
            if self.verbose:
                print(f"âœ… åºåˆ— {sequence_name} è¯„ä¼°æˆåŠŸ")
            
            return results
            
        except Exception as e:
            print(f"âŒ åºåˆ— {sequence_name} è¯„ä¼°å¤±è´¥: {e}")
            if self.verbose:
                import traceback
                traceback.print_exc()
            return None
    
    def evaluate_all_sequences(self, output_summary_dir=None):
        """
        è¯„ä¼°æ‰€æœ‰åºåˆ—
        
        Args:
            output_summary_dir: æ€»ç»“æžœè¾“å‡ºç›®å½•ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
        
        Returns:
            dict: æ‰€æœ‰åºåˆ—çš„è¯„ä¼°ç»“æžœ
        """
        if output_summary_dir is None:
            output_summary_dir = f"{self.results_base}/unified_evaluation_summary"
        
        os.makedirs(output_summary_dir, exist_ok=True)
        
        print("ðŸš€ å¼€å§‹è¯„ä¼°æ‰€æœ‰CUT3Råºåˆ—")
        print("=" * 70)
        
        all_results = {}
        successful_sequences = []
        failed_sequences = []
        
        # é€ä¸ªåºåˆ—è¯„ä¼°
        for sequence_name in tqdm(self.sequences, desc="è¯„ä¼°åºåˆ—"):
            result = self.evaluate_single_sequence(sequence_name)
            
            if result is not None:
                all_results[sequence_name] = result
                successful_sequences.append(sequence_name)
            else:
                failed_sequences.append(sequence_name)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        summary = self._generate_summary_report(all_results, successful_sequences, failed_sequences)
        
        # ä¿å­˜æ€»ç»“æžœ
        summary_file = os.path.join(output_summary_dir, 'cut3r_evaluation_summary.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = os.path.join(output_summary_dir, 'cut3r_evaluation_report.txt')
        self._save_detailed_report(summary, report_file)
        
        # æ‰“å°æ€»ç»“
        self._print_summary(summary)
        
        print(f"\nðŸ“ è¯¦ç»†ç»“æžœå·²ä¿å­˜åˆ°: {output_summary_dir}")
        
        return all_results
    
    def _generate_summary_report(self, all_results, successful_sequences, failed_sequences):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        # æ”¶é›†æ‰€æœ‰æˆåŠŸåºåˆ—çš„æŒ‡æ ‡
        depth_metrics = []
        gate_rmses = []
        late_rmse_means = []
        late_rmse_stds = []
        
        for seq_name, result in all_results.items():
            depth_eval = result['depth_evaluation']
            pose_eval = result['pose_evaluation']['pose_metrics']
            
            # é€‰æ‹©æ·±åº¦æŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨åˆ†æ®µè¯„ä¼°ç»“æžœï¼‰
            if 'depth_metrics_segmented' in depth_eval:
                depth_metrics_data = depth_eval['depth_metrics_segmented']
            else:
                depth_metrics_data = depth_eval['depth_metrics']
            
            # æ·±åº¦æŒ‡æ ‡
            depth_metrics.append({
                'sequence': seq_name,
                'abs_rel': depth_metrics_data['abs_rel']['mean'],
                'sq_rel': depth_metrics_data['sq_rel']['mean'],
                'rmse': depth_metrics_data['rmse']['mean'],
                'rmse_log': depth_metrics_data['rmse_log']['mean'],
                'a1': depth_metrics_data['a1']['mean'],
                'a2': depth_metrics_data['a2']['mean'],
                'a3': depth_metrics_data['a3']['mean']
            })
            
            # ä½å§¿æŒ‡æ ‡
            gate_rmses.append(pose_eval['gate']['gate_rmse'])
            late_rmse_means.append(pose_eval['late']['late_rmse_mean'])
            late_rmse_stds.append(pose_eval['late']['late_rmse_std'])
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        if len(depth_metrics) > 0:
            avg_depth_metrics = {
                'abs_rel': np.mean([m['abs_rel'] for m in depth_metrics]),
                'sq_rel': np.mean([m['sq_rel'] for m in depth_metrics]),
                'rmse': np.mean([m['rmse'] for m in depth_metrics]),
                'rmse_log': np.mean([m['rmse_log'] for m in depth_metrics]),
                'a1': np.mean([m['a1'] for m in depth_metrics]),
                'a2': np.mean([m['a2'] for m in depth_metrics]),
                'a3': np.mean([m['a3'] for m in depth_metrics])
            }
            
            avg_pose_metrics = {
                'gate_rmse': np.mean(gate_rmses),
                'late_rmse_mean': np.mean(late_rmse_means),
                'late_rmse_std': np.mean(late_rmse_stds)
            }
        else:
            avg_depth_metrics = {}
            avg_pose_metrics = {}
        
        summary = {
            'evaluation_info': {
                'total_sequences': len(self.sequences),
                'successful_sequences': len(successful_sequences),
                'failed_sequences': len(failed_sequences),
                'success_rate': len(successful_sequences) / len(self.sequences)
            },
            'successful_sequences': successful_sequences,
            'failed_sequences': failed_sequences,
            'average_metrics': {
                'depth': avg_depth_metrics,
                'pose': avg_pose_metrics
            },
            'per_sequence_metrics': {
                'depth': depth_metrics,
                'pose': {
                    'gate_rmses': gate_rmses,
                    'late_rmse_means': late_rmse_means,
                    'late_rmse_stds': late_rmse_stds
                }
            }
        }
        
        return summary
    
    def _save_detailed_report(self, summary, report_file):
        """ä¿å­˜è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š"""
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CUT3Ræ¨¡åž‹è¯„ä¼°æŠ¥å‘Š - ç»Ÿä¸€è¯„ä¼°æ¡†æž¶\n")
            f.write("=" * 80 + "\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            info = summary['evaluation_info']
            f.write(f"è¯„ä¼°åºåˆ—æ€»æ•°: {info['total_sequences']}\n")
            f.write(f"æˆåŠŸè¯„ä¼°: {info['successful_sequences']}\n")
            f.write(f"å¤±è´¥è¯„ä¼°: {info['failed_sequences']}\n")
            f.write(f"æˆåŠŸçŽ‡: {info['success_rate']:.1%}\n\n")
            
            if info['failed_sequences'] > 0:
                f.write("å¤±è´¥åºåˆ—:\n")
                for seq in summary['failed_sequences']:
                    f.write(f"  - {seq}\n")
                f.write("\n")
            
            # å¹³å‡æŒ‡æ ‡
            if summary['average_metrics']['depth']:
                depth_avg = summary['average_metrics']['depth']
                pose_avg = summary['average_metrics']['pose']
                
                f.write("ðŸŽ¯ å¹³å‡è¯„ä¼°ç»“æžœ:\n")
                f.write("-" * 50 + "\n")
                f.write("æ·±åº¦æŒ‡æ ‡ (å•ä½è¯´æ˜Ž: rmseå•ä½ä¸ºç±³m):\n")
                f.write(f"  abs_rel:  {depth_avg['abs_rel']:.4f}\n")
                f.write(f"  sq_rel:   {depth_avg['sq_rel']:.4f}\n")
                f.write(f"  rmse:     {depth_avg['rmse']:.4f} m\n")
                f.write(f"  rmse_log: {depth_avg['rmse_log']:.4f}\n")
                f.write(f"  a1:       {depth_avg['a1']:.4f}\n")
                f.write(f"  a2:       {depth_avg['a2']:.4f}\n")
                f.write(f"  a3:       {depth_avg['a3']:.4f}\n\n")
                
                f.write("ä½å§¿æŒ‡æ ‡:\n")
                f.write(f"  G-ATE RMSE: {pose_avg['gate_rmse']:.4f} m\n")
                f.write(f"  L-ATE RMSE: {pose_avg['late_rmse_mean']:.4f} Â± {pose_avg['late_rmse_std']:.4f} m\n\n")
            
            # æ¯ä¸ªåºåˆ—çš„è¯¦ç»†ç»“æžœ
            f.write("ðŸ“Š å„åºåˆ—è¯¦ç»†ç»“æžœ:\n")
            f.write("-" * 50 + "\n")
            for depth_metric in summary['per_sequence_metrics']['depth']:
                seq = depth_metric['sequence']
                f.write(f"{seq}:\n")
                f.write(f"  æ·±åº¦: abs_rel={depth_metric['abs_rel']:.4f}, rmse={depth_metric['rmse']:.4f}m, a1={depth_metric['a1']:.4f}\n")
                
                # æ‰¾åˆ°å¯¹åº”çš„ä½å§¿æŒ‡æ ‡
                seq_idx = summary['successful_sequences'].index(seq)
                gate_rmse = summary['per_sequence_metrics']['pose']['gate_rmses'][seq_idx]
                late_mean = summary['per_sequence_metrics']['pose']['late_rmse_means'][seq_idx]
                late_std = summary['per_sequence_metrics']['pose']['late_rmse_stds'][seq_idx]
                f.write(f"  ä½å§¿: G-ATE={gate_rmse:.4f}m, L-ATE={late_mean:.4f}Â±{late_std:.4f}m\n\n")
    
    def _print_summary(self, summary):
        """æ‰“å°è¯„ä¼°æ€»ç»“"""
        print("\n" + "=" * 80)
        print("ðŸŽ‰ CUT3Ræ¨¡åž‹è¯„ä¼°å®Œæˆ - æ€»ç»“æŠ¥å‘Š")
        print("=" * 80)
        
        info = summary['evaluation_info']
        print(f"ðŸ“Š è¯„ä¼°ç»Ÿè®¡:")
        print(f"  æ€»åºåˆ—æ•°: {info['total_sequences']}")
        print(f"  æˆåŠŸè¯„ä¼°: {info['successful_sequences']}")
        print(f"  æˆåŠŸçŽ‡: {info['success_rate']:.1%}")
        
        if info['failed_sequences'] > 0:
            print(f"  å¤±è´¥åºåˆ—: {summary['failed_sequences']}")
        
        if summary['average_metrics']['depth']:
            depth_avg = summary['average_metrics']['depth']
            pose_avg = summary['average_metrics']['pose']
            
            print(f"\nðŸŽ¯ å¹³å‡æ€§èƒ½æŒ‡æ ‡:")
            print(f"  æ·±åº¦ä¼°è®¡ (å•ä½è¯´æ˜Ž: rmseå•ä½ä¸ºç±³m):")
            print(f"    abs_rel:  {depth_avg['abs_rel']:.4f}")
            print(f"    sq_rel:   {depth_avg['sq_rel']:.4f}")
            print(f"    rmse:     {depth_avg['rmse']:.4f} m")
            print(f"    rmse_log: {depth_avg['rmse_log']:.4f}")
            print(f"    a1:       {depth_avg['a1']:.4f}")
            print(f"    a2:       {depth_avg['a2']:.4f}")
            print(f"    a3:       {depth_avg['a3']:.4f}")
            
            print(f"  ä½å§¿ä¼°è®¡:")
            print(f"    G-ATE:    {pose_avg['gate_rmse']:.4f} m")
            print(f"    L-ATE:    {pose_avg['late_rmse_mean']:.4f} Â± {pose_avg['late_rmse_std']:.4f} m")
            
            # æ€§èƒ½è¯„çº§
            print(f"\nðŸ† æ€§èƒ½è¯„çº§:")
            if depth_avg['a1'] > 0.8:
                depth_grade = "ä¼˜ç§€ (Sçº§)"
            elif depth_avg['a1'] > 0.6:
                depth_grade = "è‰¯å¥½ (Açº§)"
            else:
                depth_grade = "æœ‰å¾…æ”¹è¿› (Bçº§)"
            print(f"  æ·±åº¦ä¼°è®¡: {depth_grade} (a1={depth_avg['a1']:.3f})")
            
            if pose_avg['gate_rmse'] < 0.01 and pose_avg['late_rmse_mean'] < 0.01:
                pose_grade = "ä¼˜ç§€ (Sçº§)"
            elif pose_avg['gate_rmse'] < 0.05 and pose_avg['late_rmse_mean'] < 0.05:
                pose_grade = "è‰¯å¥½ (Açº§)"
            else:
                pose_grade = "æœ‰å¾…æ”¹è¿› (Bçº§)"
            print(f"  ä½å§¿ä¼°è®¡: {pose_grade}")
        
        print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CUT3Rç»“æžœè¯„ä¼°å·¥å…·')
    parser.add_argument('--sequence', type=str, help='è¯„ä¼°ç‰¹å®šåºåˆ—ï¼Œå¦‚æžœä¸æŒ‡å®šåˆ™è¯„ä¼°æ‰€æœ‰åºåˆ—')
    parser.add_argument('--output', type=str, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = CUT3RResultsEvaluator(verbose=args.verbose)
    
    if args.sequence:
        # è¯„ä¼°å•ä¸ªåºåˆ—
        if args.sequence not in evaluator.sequences:
            print(f"âŒ åºåˆ— '{args.sequence}' ä¸åœ¨æ”¯æŒçš„åºåˆ—åˆ—è¡¨ä¸­")
            print(f"æ”¯æŒçš„åºåˆ—: {evaluator.sequences}")
            return
        
        result = evaluator.evaluate_single_sequence(args.sequence)
        if result:
            print(f"âœ… åºåˆ— {args.sequence} è¯„ä¼°å®Œæˆ")
            # æ‰“å°ç®€è¦ç»“æžœ
            evaluator.evaluator.print_complete_results(result)
    else:
        # è¯„ä¼°æ‰€æœ‰åºåˆ—
        all_results = evaluator.evaluate_all_sequences(args.output)
        print(f"âœ… æ‰€æœ‰åºåˆ—è¯„ä¼°å®Œæˆï¼ŒæˆåŠŸè¯„ä¼° {len(all_results)} ä¸ªåºåˆ—")


if __name__ == "__main__":
    main()
